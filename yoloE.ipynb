{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLOE\n",
    "from ultralytics.models.yolo.yoloe import YOLOEVPSegPredictor\n",
    "import supervision as sv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест детекции с текстовым промптом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.139  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLOe-11l-seg summary (fused): 227 layers, 35,117,862 parameters, 2,254,374 gradients, 144.1 GFLOPs\n",
      "\n",
      "image 1/1 d:\\my_cv_projecs\\yolo\\sample_substraction\\19176.jpg: 480x640 1 \n",
      "Russian car license plate: \n",
      "- white rectangular-shape metal plate\n",
      "- black cyrillic characters\n",
      "- format: 1 letter, 3 digits, 2 letters, regional code\n",
      "- example: A 123 BC 77 RUS\n",
      "- mounted with visible bolts/screws\n",
      ", 34.6ms\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLOE(\"yoloe-11l-seg.pt\")\n",
    "image_size = (640, 640)\n",
    "image = 'sample_substraction/19176.jpg'\n",
    "license_plate_prompt = \"\"\"\n",
    "Russian car license plate: \n",
    "- white rectangular-shape metal plate\n",
    "- black cyrillic characters\n",
    "- format: 1 letter, 3 digits, 2 letters, regional code\n",
    "- example: A 123 BC 77 RUS\n",
    "- mounted with visible bolts/screws\n",
    "\"\"\"\n",
    "classes = [license_plate_prompt]\n",
    "# Вместе с промптами - передаем эмбеддинги текста\n",
    "model.set_classes(classes, model.get_text_pe(classes))\n",
    "results = model.predict(image, imgsz = image_size)\n",
    "detections = sv.Detections.from_ultralytics(results[0])\n",
    "\n",
    "annotator = sv.BoxAnnotator()\n",
    "# Для выделения сегмента - пайплайн по сути отличается только дополнительным сегментированием объекта\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "labels = [f'{confidence:.2f}' \n",
    "          for confidence \n",
    "          in detections.confidence]\n",
    "\n",
    "image_for_labeling = cv2.imread(image)\n",
    "image_with_bounding_boxes = annotator.annotate(scene = image_for_labeling, \n",
    "                                               detections = detections)\n",
    "segmented_image_with_bounding_boxes = mask_annotator.annotate(scene = image_with_bounding_boxes,\n",
    "                                                              detections = detections)\n",
    "labeled_image = label_annotator.annotate(scene = segmented_image_with_bounding_boxes, \n",
    "                                         detections = detections,\n",
    "                                         labels = labels)\n",
    "cv2.imwrite('labeled_by_text_prompt.jpg', labeled_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест детекции с визуальным промптом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.139  Python-3.11.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLOe-11l-seg summary (fused): 227 layers, 35,117,862 parameters, 2,254,374 gradients\n",
      "\n",
      "image 1/1 d:\\my_cv_projecs\\yolo\\sample_substraction\\19176.jpg: 480x640 1 object0, 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLOE(\"yoloe-11l-seg.pt\")\n",
    "image_size = (640, 640)\n",
    "target_image = 'sample_substraction/19176.jpg'\n",
    "refer_image = 'sample_substraction/10515.jpg'\n",
    "\n",
    "xyxy_boxes_coords = np.array([[358.7, 513.11, 594.8, 580.85]])\n",
    "\n",
    "# Визуальный промпт для модели - указываются координаты целевого объекта и класс объекта\n",
    "# bboxes - нужно подавать координаты в формате XYXY (x1, y1, x2, y2)\n",
    "# TODO детально изучить, как формировать универсальные промпты, \n",
    "# подходящие под различные кейсы расположения объекта\n",
    "visual_prompts = dict(\n",
    "    bboxes = xyxy_boxes_coords,\n",
    "    cls = np.array([0])\n",
    ")\n",
    "\n",
    "# Запускаем прогноз модели с использованием визуального промпта\n",
    "results = model.predict(\n",
    "    source = target_image,\n",
    "    refer_image = refer_image,\n",
    "    visual_prompts = visual_prompts,\n",
    "    imgsz = image_size,\n",
    "    predictor = YOLOEVPSegPredictor\n",
    ")\n",
    "\n",
    "detections = sv.Detections.from_ultralytics(results[0])\n",
    "\n",
    "annotator = sv.BoxAnnotator()\n",
    "# Для выделения сегмента - пайплайн по сути отличается только дополнительным сегментированием объекта\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "labels = [f'{confidence:.2f}' \n",
    "          for confidence \n",
    "          in detections.confidence]\n",
    "\n",
    "image_for_labeling = cv2.imread(target_image)\n",
    "image_with_bounding_boxes = annotator.annotate(scene = image_for_labeling, \n",
    "                                               detections = detections)\n",
    "segmented_image_with_bounding_boxes = mask_annotator.annotate(scene = image_with_bounding_boxes,\n",
    "                                                              detections = detections)\n",
    "labeled_image = label_annotator.annotate(scene = segmented_image_with_bounding_boxes, \n",
    "                                         detections = detections,\n",
    "                                         labels = labels)\n",
    "cv2.imwrite('labeled_by_visual_prompt.jpg', labeled_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
