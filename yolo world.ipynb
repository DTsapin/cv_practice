{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLOWorld\n",
    "import supervision as sv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к изображениям\n",
    "PATH_TO_IMAGES = \"sample_substraction\"\n",
    "PATH_TO_DEBUG = \"debug\"\n",
    "BATCH_SIZE = 5\n",
    "# Список картинок\n",
    "list_of_images = os.listdir(PATH_TO_IMAGES)\n",
    "list_of_images_with_relative_path = [os.path.join(PATH_TO_IMAGES, image) for image in list_of_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 license_plates, 49.5ms\n",
      "1: 640x640 2 license_plates, 49.5ms\n",
      "2: 640x640 2 license_plates, 49.5ms\n",
      "3: 640x640 2 license_plates, 49.5ms\n",
      "4: 640x640 3 license_plates, 49.5ms\n",
      "5: 640x640 2 license_plates, 49.5ms\n",
      "Speed: 4.0ms preprocess, 49.5ms inference, 33.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license_plates, 46.7ms\n",
      "1: 640x640 2 license_plates, 46.7ms\n",
      "2: 640x640 5 license_plates, 46.7ms\n",
      "3: 640x640 3 license_plates, 46.7ms\n",
      "4: 640x640 3 license_plates, 46.7ms\n",
      "5: 640x640 2 license_plates, 46.7ms\n",
      "Speed: 3.7ms preprocess, 46.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license_plates, 47.0ms\n",
      "1: 640x640 2 license_plates, 47.0ms\n",
      "2: 640x640 2 license_plates, 47.0ms\n",
      "3: 640x640 5 license_plates, 47.0ms\n",
      "4: 640x640 2 license_plates, 47.0ms\n",
      "5: 640x640 3 license_plates, 47.0ms\n",
      "Speed: 3.4ms preprocess, 47.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 license_plates, 46.8ms\n",
      "1: 640x640 2 license_plates, 46.8ms\n",
      "2: 640x640 2 license_plates, 46.8ms\n",
      "3: 640x640 4 license_plates, 46.8ms\n",
      "4: 640x640 2 license_plates, 46.8ms\n",
      "5: 640x640 2 license_plates, 46.8ms\n",
      "Speed: 2.9ms preprocess, 46.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 license_plates, 50.2ms\n",
      "1: 640x640 2 license_plates, 50.2ms\n",
      "2: 640x640 2 license_plates, 50.2ms\n",
      "3: 640x640 4 license_plates, 50.2ms\n",
      "4: 640x640 2 license_plates, 50.2ms\n",
      "Speed: 3.7ms preprocess, 50.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "model = YOLOWorld(\"yolov8x-worldv2.pt\")\n",
    "\n",
    "# Задаем промпт для модели\n",
    "classes = [\"license_plate\", \"\"]\n",
    "model.set_classes(classes)\n",
    "\n",
    "# Создаем датасет\n",
    "dataset = sv.DetectionDataset(classes=classes, \n",
    "                              images=list_of_images_with_relative_path, \n",
    "                              annotations={list_of_images_with_relative_path[i]: None \n",
    "                                           for i in range(len(list_of_images_with_relative_path))})\n",
    "\n",
    "for i in range(0, len(list_of_images_with_relative_path), BATCH_SIZE):\n",
    "    batch = list_of_images_with_relative_path[i:BATCH_SIZE+i+1]\n",
    "    lst_of_cv2_instances = [cv2.imread(image) for image in batch]\n",
    "\n",
    "    # Запускаем детекцию с порогом уверенности\n",
    "    results = model.predict(lst_of_cv2_instances, conf=0.1, imgsz=(640, 640))\n",
    "\n",
    "    for index in range(len(results)):\n",
    "        # Получение детекций для Supervision\n",
    "        detections = sv.Detections.from_ultralytics(results[index])\n",
    "\n",
    "        # фильтрация детекций по ширине bounding-box-а\n",
    "        w = detections.xyxy[:, 2] - detections.xyxy[:, 0]\n",
    "        h = detections.xyxy[:, 3] - detections.xyxy[:, 1]\n",
    "\n",
    "        # TODO подобрано эмпирически, надо разобраться\n",
    "        detections = detections[(w < 500)]\n",
    "\n",
    "        #  Non-Maximum Suppression (NMS) постобработка для удаления дублирующихся прямоугольников\n",
    "        filtered_detections = detections.with_nms(threshold=0.5)\n",
    "\n",
    "        # Инициализация экземпляров классов для боксов и подписей\n",
    "        annotator = sv.BoxAnnotator()\n",
    "        label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "        # вывод доп информации (уверенность)\n",
    "        labels = [\n",
    "            f\"{class_name} {confidence:.2f}\"\n",
    "            for class_name, confidence\n",
    "            in zip(filtered_detections['class_name'], filtered_detections.confidence)\n",
    "        ]\n",
    "\n",
    "        # Непосредственно, рисуем боксы и подписи\n",
    "        annotated_image = annotator.annotate(scene = lst_of_cv2_instances[index], \n",
    "                                            detections = filtered_detections)\n",
    "        annotated_image = label_annotator.annotate(scene = annotated_image, \n",
    "                                                detections = filtered_detections, \n",
    "                                                labels=labels)\n",
    "\n",
    "        # Сохраняем размеченную картинку\n",
    "        cv2.imwrite(f\"{PATH_TO_DEBUG}/annotated_{batch[index]}\", annotated_image)\n",
    "\n",
    "        # Вносим в датасет инфу по детекциям для конкретной картинки\n",
    "        dataset.annotations[batch[index]] = filtered_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Экспортируем в YOLO-формат (data_yaml генерируется невалидный для CVAT, нужно создавать самому)\n",
    "dataset.as_yolo(\n",
    "    images_directory_path=\"subbatch_license_plate_dataset/images/train\",\n",
    "    annotations_directory_path=\"subbatch_license_plate_dataset/labels/train\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
